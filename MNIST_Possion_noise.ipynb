{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "# from pytorch_lightning import seed_everything\n",
    "# seed_everything(123)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddPoissonNoise(object):\n",
    "    def __init__(self, scale=255):\n",
    "        \"\"\"\n",
    "        Initialize the AddPoissonNoise class.\n",
    "        :param scale: The scale factor to adjust the intensity of the noise.\n",
    "        \"\"\"\n",
    "        self.scale = scale\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Add Poisson noise to the tensor.\n",
    "        :param tensor: Input tensor with values scaled between 0 and 1.\n",
    "        :return: Tensor with Poisson noise added.\n",
    "        \"\"\"\n",
    "        tensor_scaled = tensor * self.scale\n",
    "        noise = torch.poisson(tensor_scaled) - tensor_scaled\n",
    "        return (tensor + noise / self.scale).clamp(0, 1)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(scale={0})'.format(self.scale)\n",
    "class AddSaltAndPepperNoise(object):\n",
    "    def __init__(self, salt_pepper_ratio=0.5, amount=0.02):\n",
    "        \"\"\"\n",
    "        Initialize the AddSaltAndPepperNoise class.\n",
    "        :param salt_pepper_ratio: Ratio of salt (white) to pepper (black) noise.\n",
    "        :param amount: Proportion of image pixels to replace with noise.\n",
    "        \"\"\"\n",
    "        self.salt_pepper_ratio = salt_pepper_ratio\n",
    "        self.amount = amount\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Add Salt and Pepper noise to the tensor.\n",
    "        :param tensor: Input tensor.\n",
    "        :return: Tensor with Salt and Pepper noise added.\n",
    "        \"\"\"\n",
    "        noise = torch.rand_like(tensor)\n",
    "        salt_pepper = torch.rand_like(tensor)\n",
    "\n",
    "        # Add Salt noise\n",
    "        noisy_tensor = torch.where((salt_pepper < self.amount * self.salt_pepper_ratio), torch.ones_like(tensor), tensor)\n",
    "\n",
    "        # Add Pepper noise\n",
    "        noisy_tensor = torch.where((salt_pepper < self.amount) & (salt_pepper >= self.amount * self.salt_pepper_ratio), torch.zeros_like(tensor), noisy_tensor)\n",
    "\n",
    "        return noisy_tensor\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(salt_pepper_ratio={0}, amount={1})'.format(self.salt_pepper_ratio, self.amount)\n",
    "class AddMultiplicativeNoise(object):\n",
    "    def __init__(self, mean=1.0, std=0.1):\n",
    "        \"\"\"\n",
    "        Initialize the AddMultiplicativeNoise class.\n",
    "        :param mean: Mean of the multiplicative noise.\n",
    "        :param std: Standard deviation of the multiplicative noise.\n",
    "        \"\"\"\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Add multiplicative noise to the tensor.\n",
    "        :param tensor: Input tensor.\n",
    "        :return: Tensor with multiplicative noise added.\n",
    "        \"\"\"\n",
    "        noise = torch.randn(tensor.size()) * self.std + self.mean\n",
    "        return tensor * noise\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(), # Convert PIL image to Tensor\n",
    "    AddMultiplicativeNoise() # Add Gaussian noise\n",
    "])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor() # Convert PIL image to Tensor   \n",
    "])\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train\n",
    ")\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test\n",
    ")\n",
    "test_data1 = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_train\n",
    ")\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size)\n",
    "test_dataloader1 = DataLoader(dataset=test_data1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "iter_dataloader = iter(test_dataloader)\n",
    "\n",
    "n=1\n",
    "\n",
    "# 取出n*batch_size张图片可视化\n",
    "for i in range(n):\n",
    "    images, labels = next(iter_dataloader)\n",
    "    image_grid = torchvision.utils.make_grid(images,nrow=4)\n",
    "    plt.figure(figsize=(5, 5), dpi=80)\n",
    "    plt.subplot(1, n, i+1)\n",
    "    plt.imshow(np.transpose(image_grid.numpy(), (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.savefig('MNIST_org_possion.pdf')\n",
    "    plt.show()\n",
    "iter_dataloader = iter(test_dataloader1)\n",
    "for i in range(n):\n",
    "    images, labels = next(iter_dataloader)\n",
    "    # print(images)\n",
    "    image_grid = torchvision.utils.make_grid(images,nrow=4)\n",
    "    plt.figure(figsize=(5, 5), dpi=80)\n",
    "    plt.subplot(1, n, i+1)\n",
    "    plt.imshow(np.transpose(image_grid.numpy(), (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.savefig('MNIST_noisy_possion.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, heatup = False):\n",
    "        super(LeNet,self).__init__()\n",
    "        self.heatup = heatup\n",
    "        # self.dropout_scale = dropout_scale\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1,32,3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32,3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p = dropout_scale),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32,64,3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,64,3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout2d(p = dropout_scale),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(3136,200)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(200,10)\n",
    "\n",
    "\n",
    "    def forward(self,x, test = False, temperature_train = 0, temperature_test = 0):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        if self.heatup:\n",
    "            if test:\n",
    "                mask = torch.rand_like(out) > torch.tensor(temperature_test)\n",
    "                out = out.where(mask, -out)\n",
    "            else:\n",
    "                mask = torch.rand_like(out) > torch.tensor(temperature_train)\n",
    "                out = out.where(mask, -out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "def train(network, temperature = 0):\n",
    "    # network = LeNet(dropout_scale=dropout_scale)\n",
    "    network.train()\n",
    "    losses = []\n",
    "    iteration = 0\n",
    "    epochs = 20\n",
    "    for epoch in range(epochs):\n",
    "        loss_sum = 0\n",
    "        for i, (X, y) in enumerate(train_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = network(X, test = False, temperature_train = temperature)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        schduler.step()\n",
    "        mean_loss = loss_sum / len(train_dataloader.dataset)\n",
    "        losses.append(mean_loss)\n",
    "        iteration += 1\n",
    "        print(f\"Epoch {epoch+1} loss: {mean_loss:>7f}\")\n",
    "\n",
    "    # 训练完毕保存最后一轮训练的模型\n",
    "    torch.save(network.state_dict(), \"model.pth\")\n",
    "\n",
    "    # 绘制损失函数曲线\n",
    "    # plt.xlabel(\"Epochs\")\n",
    "    # plt.ylabel(\"Loss Value\")\n",
    "    # plt.plot(list(range(iteration)), losses)\n",
    "\n",
    "\n",
    "# if os.path.exists('model.pth'):\n",
    "#     network.load_state_dict(torch.load('model.pth'))\n",
    "# else:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(network, temperature = 0):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    network.eval()\n",
    "    for X, y in test_dataloader:\n",
    "        with torch.no_grad():\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = network(X, test= True, temperature_test = temperature)\n",
    "            pred = F.softmax(pred, dim = 1)\n",
    "            for item in zip(pred, y):\n",
    "                if torch.argmax(item[0]) == item[1]:\n",
    "                    positive += 1\n",
    "                else:\n",
    "                    negative += 1\n",
    "    acc = positive / (positive + negative)\n",
    "    print(f\"{acc * 100}%\")\n",
    "    return acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.017982\n",
      "Epoch 2 loss: 0.017603\n",
      "Epoch 3 loss: 0.004178\n",
      "Epoch 4 loss: 0.002002\n",
      "Epoch 5 loss: 0.001357\n",
      "Epoch 6 loss: 0.001019\n",
      "Epoch 7 loss: 0.000809\n",
      "Epoch 8 loss: 0.000684\n",
      "Epoch 9 loss: 0.000597\n",
      "Epoch 10 loss: 0.000532\n",
      "Epoch 11 loss: 0.000430\n",
      "Epoch 12 loss: 0.000412\n",
      "Epoch 13 loss: 0.000404\n",
      "Epoch 14 loss: 0.000398\n",
      "Epoch 15 loss: 0.000393\n",
      "Epoch 16 loss: 0.000388\n",
      "Epoch 17 loss: 0.000383\n",
      "Epoch 18 loss: 0.000378\n",
      "Epoch 19 loss: 0.000374\n",
      "Epoch 20 loss: 0.000369\n",
      "======dropout_train= 0 , dropout_test= 0 =======\n",
      "98.00999999999999%\n",
      "epsilon=0.25 acc_org: 98.00999999999999%  acc_adv: 0.52%  attack success rate:  97.49%\n",
      "Epoch 1 loss: 0.017974\n",
      "Epoch 2 loss: 0.015956\n",
      "Epoch 3 loss: 0.003901\n",
      "Epoch 4 loss: 0.002639\n",
      "Epoch 5 loss: 0.002058\n",
      "Epoch 6 loss: 0.001659\n",
      "Epoch 7 loss: 0.001388\n",
      "Epoch 8 loss: 0.001192\n",
      "Epoch 9 loss: 0.001059\n",
      "Epoch 10 loss: 0.000937\n",
      "Epoch 11 loss: 0.000812\n",
      "Epoch 12 loss: 0.000768\n",
      "Epoch 13 loss: 0.000756\n",
      "Epoch 14 loss: 0.000763\n",
      "Epoch 15 loss: 0.000753\n",
      "Epoch 16 loss: 0.000735\n",
      "Epoch 17 loss: 0.000715\n",
      "Epoch 18 loss: 0.000710\n",
      "Epoch 19 loss: 0.000708\n",
      "Epoch 20 loss: 0.000709\n",
      "======dropout_train= 0.1 , dropout_test= 0 =======\n",
      "97.21%\n",
      "epsilon=0.25 acc_org: 97.21%  acc_adv: 3.64%  attack success rate:  93.57%\n",
      "Epoch 1 loss: 0.017984\n",
      "Epoch 2 loss: 0.017896\n",
      "Epoch 3 loss: 0.010852\n",
      "Epoch 4 loss: 0.004553\n",
      "Epoch 5 loss: 0.003360\n",
      "Epoch 6 loss: 0.002589\n",
      "Epoch 7 loss: 0.002063\n",
      "Epoch 8 loss: 0.001693\n",
      "Epoch 9 loss: 0.001473\n",
      "Epoch 10 loss: 0.001300\n",
      "Epoch 11 loss: 0.001131\n",
      "Epoch 12 loss: 0.001097\n",
      "Epoch 13 loss: 0.001090\n",
      "Epoch 14 loss: 0.001083\n",
      "Epoch 15 loss: 0.001049\n",
      "Epoch 16 loss: 0.001051\n",
      "Epoch 17 loss: 0.001043\n",
      "Epoch 18 loss: 0.001028\n",
      "Epoch 19 loss: 0.001006\n",
      "Epoch 20 loss: 0.001020\n",
      "======dropout_train= 0.2 , dropout_test= 0 =======\n",
      "97.26%\n",
      "epsilon=0.25 acc_org: 97.26%  acc_adv: 9.629999999999999%  attack success rate:  87.63000000000001%\n",
      "Epoch 1 loss: 0.017988\n",
      "Epoch 2 loss: 0.017974\n",
      "Epoch 3 loss: 0.017939\n",
      "Epoch 4 loss: 0.017300\n",
      "Epoch 5 loss: 0.009005\n",
      "Epoch 6 loss: 0.006261\n",
      "Epoch 7 loss: 0.005045\n",
      "Epoch 8 loss: 0.004163\n",
      "Epoch 9 loss: 0.003540\n",
      "Epoch 10 loss: 0.003120\n",
      "Epoch 11 loss: 0.002826\n",
      "Epoch 12 loss: 0.002743\n",
      "Epoch 13 loss: 0.002677\n",
      "Epoch 14 loss: 0.002635\n",
      "Epoch 15 loss: 0.002624\n",
      "Epoch 16 loss: 0.002623\n",
      "Epoch 17 loss: 0.002543\n",
      "Epoch 18 loss: 0.002571\n",
      "Epoch 19 loss: 0.002482\n",
      "Epoch 20 loss: 0.002497\n",
      "======dropout_train= 0.3 , dropout_test= 0 =======\n",
      "96.35000000000001%\n",
      "epsilon=0.25 acc_org: 96.35000000000001%  acc_adv: 16.830000000000002%  attack success rate:  79.52%\n",
      "Epoch 1 loss: 0.017994\n",
      "Epoch 2 loss: 0.017987\n"
     ]
    }
   ],
   "source": [
    "eps_train = [0,0.1,0.2,0.3,0.4]\n",
    "eps_test =  [0]\n",
    "# eps_train = [0.2]\n",
    "# eps_test =  [0]\n",
    "# eps_test = np.arange(0.2,0.4,0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "fig1, ax1 = plt.subplots()\n",
    "fig2, ax2 = plt.subplots()\n",
    "fig3, ax3 = plt.subplots()\n",
    "for I in eps_train:\n",
    "    acc_list = []\n",
    "    acc_adv_list = []\n",
    "    success_rate_list = []\n",
    "    network = LeNet(heatup=True)\n",
    "    network.to(device)\n",
    "    optimizer = torch.optim.SGD(params=network.parameters(), lr=0.001, momentum=0.9)\n",
    "    schduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, np.arange(10,100,10), gamma=0.1)\n",
    "    train(network, temperature=I)\n",
    "    for J in eps_test:\n",
    "        print(f\"======dropout_train= {I} , dropout_test= {J} =======\")\n",
    "        acc_org = test(network,temperature=J)\n",
    "        acc_list.append(acc_org)\n",
    "        # 用对抗样本替代原始样本，测试准确度\n",
    "        # 探究不同epsilon对LeNet分类准确度的影响\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        # for epsilon in eps:\n",
    "        epsilon = 0.25\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            X.requires_grad = True\n",
    "            pred = network(X, test = True, temperature_test = J)\n",
    "            network.zero_grad()\n",
    "            loss = loss_fn(pred, y)\n",
    "            loss.backward()\n",
    "            X = X + epsilon * X.grad.sign()\n",
    "            X_adv = torch.clamp(X, 0, 1)\n",
    "            pred = network(X_adv, test = True, temperature_test = J)\n",
    "            pred = F.softmax(pred, dim = 1)\n",
    "            for item in zip(pred, y):\n",
    "                if torch.argmax(item[0]) == item[1]:\n",
    "                    positive += 1\n",
    "                else:\n",
    "                    negative += 1\n",
    "\n",
    "        acc_adv = positive / (positive + negative)\n",
    "        acc_adv_list.append(acc_adv)\n",
    "        attack_success_rate = acc_org - acc_adv\n",
    "        success_rate_list.append(attack_success_rate)\n",
    "        print(f\"epsilon={epsilon} acc_org: {acc_org * 100}%  acc_adv: {acc_adv * 100}%  attack success rate:  {attack_success_rate * 100}%\")\n",
    "    ax1.plot(eps_test, acc_list, 'o-',label = 'train%.2f'%I)\n",
    "    ax2.plot(eps_test, success_rate_list, 'o-',label = 'train%.2f'%I)\n",
    "    ax3.plot(eps_test, acc_adv_list, 'o-', label = 'train%.2f'%I)\n",
    "ax1.set_xlabel(\"Test temperature\")\n",
    "ax1.set_ylabel(\"Original test accuracy\")\n",
    "ax1.set_title('original test accuracy with test temperature')\n",
    "ax1.legend()\n",
    "ax2.set_xlabel(\"Test temperature\")\n",
    "ax2.set_ylabel(\"Atack success rate\")\n",
    "ax2.set_title('attack success rate with test temperature')\n",
    "ax2.legend()\n",
    "ax3.set_xlabel(\"Test temperature\")\n",
    "ax3.set_ylabel(\"Attack accuracy\")\n",
    "ax3.set_title('attack accuracy with test temperature')\n",
    "ax3.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python==3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
